{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fusor",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KiltCross/Line-Fuser/blob/master/Fusor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDjCaWmHAg11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "!pip install --upgrade tensorflow\n",
        "\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGWQ0PQNL9ic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGnYOXxuMJ3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import IPython.display as display\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import imageio\n",
        "\n",
        "import math \n",
        "\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXK5ZtIdO33t",
        "colab_type": "text"
      },
      "source": [
        "import the images part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYyorCR6PJn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X_1=[[1.0,1.0,1.0],[0.0,0.0,0.0],[0.0,0.0,0.0]]\n",
        "train_X_2=[[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0]]\n",
        "train_X_temp=np.transpose(\n",
        "    np.array(\n",
        "    np.concatenate(\n",
        "        (\n",
        "        np.transpose(train_X_1) , np.transpose(train_X_2)\n",
        "        )\n",
        "    ), dtype='float32')\n",
        ")\n",
        "train_Y_temp = np.array([[1,0,0],[0,1,0],[0,0,1]], dtype='float32')\n",
        "\n",
        "\n",
        "\n",
        "#Adapting the variables for the \"fit\" process\n",
        "#The framework only acept batch of three dimension, and The model only use two-dimensional batches,\n",
        "#so I decided to duplicate the images, for have three-dimensional batches\n",
        "\n",
        "train_X = np.array((train_X_temp), dtype='float32')\n",
        "train_Y = np.array([[[train_Y_temp[0,:], train_Y_temp[1,:], train_Y_temp[2,:]]]], dtype='float32').reshape(1,3,3,1)\n",
        "\n",
        "negative_train_Y = train_Y * -1 + 1\n",
        "\n",
        "#train=np.array((train_1,train_2), dtype='float32')\n",
        "\n",
        "print(train_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d6o1caaPCtN",
        "colab_type": "text"
      },
      "source": [
        "Model builder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F32jacZnPLYF",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "def generator_model():\n",
        "\n",
        "  primaty_activation_function='sigmoid'\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Dense(9, input_shape=(3,6), name='1', activation=primaty_activation_function, use_bias=False))\n",
        "  model.add(layers.Reshape((3,3,1)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Dense(180, activation=primaty_activation_function, use_bias=False))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Dense(300,activation=primaty_activation_function, use_bias=False))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(400, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(200, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Dense(3,activation='softmax', use_bias=False))\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(1, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
        "\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkTA7ZZ-WCHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_model():\n",
        "\n",
        "  primaty_activation_function='sigmoid'\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[3, 3, 1]))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1))\n",
        "\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oGwNsegSEzY",
        "colab_type": "text"
      },
      "source": [
        "Model functionality test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Axphq-RSHb_",
        "colab_type": "code",
        "outputId": "ef3f1fa9-a31c-42ea-c1d7-1c68b650a9cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "generator = generator_model()\n",
        "\n",
        "discriminator = discriminator_model()\n",
        "\n",
        "#discriminator.summary()\n",
        "\n",
        "#generator.summary()\n",
        "\n",
        "generated_image = generator(train_X_temp, training=False)\n",
        "\n",
        "result = discriminator(generated_image, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0,:,:,0], cmap='gray')\n",
        "\n",
        "print(generated_image[0,:,:,0])\n",
        "\n",
        "#print(train_X)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-6c8be7797702>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#discriminator.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'discriminator_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aQkl2yPlCAb",
        "colab_type": "text"
      },
      "source": [
        "Setting some useful varibles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4wdZWlKk68n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Epoch=1000\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "mean_squared = tf.keras.losses.mean_squared_error\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47Rp4vH2YDrE",
        "colab_type": "text"
      },
      "source": [
        "Setting the generator loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXriaF30YNVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss_function(fake_output, real_image, fake_image, negative_image):\n",
        "    real_loss = cross_entropy(real_image[0,:,:,0], fake_image[0,:,:,0])\n",
        "    fake_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "    negative_loss = cross_entropy(negative_image[0,:,:,0], fake_image[0,:,:,0])**-1\n",
        "    total_loss = real_loss + fake_loss + negative_image\n",
        "    return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ3Dns52YSKp",
        "colab_type": "text"
      },
      "source": [
        "Setting the discriminator loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lKbmZidYZCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss_function(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLRVrfBqvQUQ",
        "colab_type": "text"
      },
      "source": [
        "Train function part 1 of 2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADZznQ4IsB-E",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "@tf.function\n",
        "def train_step(image_X, image_Y, image_negative_Y):\n",
        "    with tf.GradientTape() as generator_tape, tf.GradientTape() as discriminator_tape:\n",
        "\n",
        "      generated_images = generator(image_X, training=True)\n",
        "\n",
        "      real_output = discriminator(image_Y, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      generator_loss = generator_loss_function(fake_output, image_Y, generated_images, image_negative_Y)\n",
        "      discriminator_loss = discriminator_loss_function(real_output, fake_output)\n",
        "      print(generator_loss)\n",
        "\n",
        "\n",
        "      #Here I use the a inverse loss function to make the model move away from the negative examples\n",
        "\n",
        "    gradients_of_generator = generator_tape.gradient(generator_loss, generator.trainable_variables)\n",
        "\n",
        "    gradients_of_discriminator = discriminator_tape.gradient(discriminator_loss, discriminator.trainable_variables)\n",
        "\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    #optimizer.minimize(loss, generator.trainable_variables)\n",
        "\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ULZcozm2Da2",
        "colab_type": "text"
      },
      "source": [
        "Train function part 2 of 2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GVgNv8a2ZOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(images_X, images_Y, images_negative_Y, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    train_step(images_X, images_Y, images_negative_Y)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSPb5TtXWDUu",
        "colab_type": "text"
      },
      "source": [
        "Train test part:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-ubHhjUWLa_",
        "colab_type": "code",
        "outputId": "65bfd5a0-157d-4c90-826f-aac14df477f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "source": [
        "#fitting the model\n",
        "\n",
        "train(train_X, train_Y, negative_train_Y, Epoch)\n",
        "\n",
        "#Print the result\n",
        "\n",
        "generated_image = generator(train_X_temp, training=True)\n",
        "\n",
        "plt.imshow(generated_image[0,:,:,0], cmap='gray')\n",
        "\n",
        "print(generated_image[0,:,:,0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape Tensor(\"1_input_2:0\", shape=(None, 3, 6), dtype=float32) for input (None, 3, 6), but it was re-called on a Tensor with incompatible shape (3, 6).\n",
            "tf.Tensor(\n",
            "[[ 9.9739003e-01  1.4121762e-02 -1.0295431e-03]\n",
            " [ 3.8382965e-03  9.9770224e-01 -5.4230529e-04]\n",
            " [-3.0381975e-04 -4.3839090e-02  9.9762964e-01]], shape=(3, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTQwPSU0MD0lNDA9JTQwPSU0MD0lN/h/Gsf6US0vegAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL7eHBC8RVIY",
        "colab_type": "code",
        "outputId": "3774c703-e256-42fa-98ce-dd5890ce4f42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print([3**-1])\n",
        "\n",
        "\n",
        "print(generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.3333333333333333]\n",
            "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f935632aa90>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}